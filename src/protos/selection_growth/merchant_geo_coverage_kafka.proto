syntax = "proto3";

// buf:lint:ignore DIRECTORY_SAME_PACKAGE
package selection_growth_service.kafka.v1;

import "common/service_client_config.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/wrappers.proto";
import "selection_growth/common.proto";

option java_generic_services = true;
option java_multiple_files = true;
option java_package = "com.doordash.rpc.selectiongrowthgrpc";

// KAFKA event for merchant geo coverage
message MerchantIsoCoverageEvent {
  // coverage data
  selection_growth_service.common.v1.CoverageData data = 1;
  // timestamp will be used for the latency tracking
  // iso v1 batch -> timestamp start processing the mx
  // iso v1 delta -> timestamp of the mds kafka event
  // iso v2 batch -> timestamp start processing the mx
  // iso v2 delta -> detailed tracking timestamp referring to delta_time_stamp
  google.protobuf.Timestamp timestamp = 4;
  // flag for priority event
  bool is_priority_event = 5;
  // flag for delta job
  bool is_delta = 6;
  // iso v2 delta time stamps specifically for delta iso v2
  DeltaJobTimestamp delta_time_stamp = 7;
  // iso jog version
  bool is_v2 = 8;
}

// DeltaJobTimestamp message definition
message DeltaJobTimestamp {
  // timestamp for s3_upload
  google.protobuf.Timestamp s3_upload_timestamp = 1;
  // timestamp for kafka event
  google.protobuf.Timestamp last_event_timestamp = 2;
  // timestamp when databricks job start
  google.protobuf.Timestamp databricks_start_timestamp = 3;
  // timestamp when databricks job finish
  google.protobuf.Timestamp databricks_end_timestamp = 4;
  // timestamp when publish the event
  google.protobuf.Timestamp delta_coverage_publish_timestamp = 5;
}
