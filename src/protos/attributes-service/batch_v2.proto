syntax = "proto3";

// buf:lint:ignore DIRECTORY_SAME_PACKAGE
package attributes_service.v2;

import "attributes-service/common.proto";
import "google/protobuf/timestamp.proto";

option go_package = "attributes_service";
option java_generic_services = true;
option java_multiple_files = true;
option java_outer_classname = "JobServiceProto";
option java_package = "com.doordash.rpc.attributes_service.v2";

// JobService is the service manage attributes within dx&logistics org
service JobService {
  //Read API to get the batch job
  rpc GetBatchJobs(GetBatchJobsRequest) returns (GetBatchJobsResponse);

  //Read API to get the batch job run details
  rpc GetBatchJobRunDetails(GetBatchJobRunDetailsRequest) returns (GetBatchJobRunDetailsResponse);

  //Write API to onboard the new batchJob
  rpc UpsertBatchJob(UpsertBatchJobRequest) returns (UpsertBatchJobResponse);

  //Write API to upsert the job run details
  rpc UpsertBatchJobRunDetails(UpsertBatchJobRunDetailsRequest) returns (UpsertBatchJobRunDetailsResponse);
}

// Request payload for UpsertBatchJob API
message UpsertBatchJobRequest {
  // batch job request
  BatchJob job = 1;
}

// API response to UpsertBatchJob
message UpsertBatchJobResponse {
  // unique job identifier
  string job_id = 1;
}

// Request payload for GetBatchJob API
message BatchJob {
  // user friendly job name
  string job_name = 1;
  // ownership information
  Owner owner = 2;
  // unique identifier for this job
  JobMetadata job_metadata = 3;
  // current state of the job
  BatchJobState current_state = 4;
  // current state of the job
  string sql_payload = 5;
}

// BatchJobState definitions
enum BatchJobState {
  // unknown schedule
  BATCH_JOB_STATE_UNSPECIFIED = 0 [(attributes_service.common.v1.value) = "UnknownBatchJobState"];

  // Submitted received request yet to be scheduled
  BATCH_JOB_STATE_SUBMITTED = 1 [(attributes_service.common.v1.value) = "Submitted"];

  // Scheduled to run on the given cron schedule
  BATCH_JOB_STATE_SCHEDULED = 2 [(attributes_service.common.v1.value) = "Scheduled"];

  // Job has been Disabled
  BATCH_JOB_STATE_DISABLED = 3 [(attributes_service.common.v1.value) = "Disabled"];

  // the job has been Deleted
  BATCH_JOB_STATE_DELETED = 4 [(attributes_service.common.v1.value) = "Deleted"];
}

// JobSchedule definitions
enum JobSchedule {
  // unknown schedule
  JOB_SCHEDULE_UNSPECIFIED = 0 [(attributes_service.common.v1.value) = "UnspecifiedSchedule"];

  // HOURLY
  JOB_SCHEDULE_HOURLY = 1 [(attributes_service.common.v1.value) = "OnceEveryHour"];

  // DAILY
  JOB_SCHEDULE_DAILY = 2 [(attributes_service.common.v1.value) = "OnceEveryDay"];

  // WEEKLY
  JOB_SCHEDULE_WEEKLY = 3 [(attributes_service.common.v1.value) = "OnceEveryWeek"];

  // MONTHLY
  JOB_SCHEDULE_MONTHLY = 4 [(attributes_service.common.v1.value) = "OnceEveryMonth"];
}

// DataSource
enum DataSource {
  // unknown datasource
  DATA_SOURCE_UNSPECIFIED = 0 [(attributes_service.common.v1.value) = "UnknownDataSource"];

  // snowflake datasource
  DATA_SOURCE_SNOWFLAKE = 1 [(attributes_service.common.v1.value) = "Snowflake"];

  // trino datasource
  DATA_SOURCE_TRINO = 2 [(attributes_service.common.v1.value) = "Trino"];

  // spark datasource
  DATA_SOURCE_SPARK = 3 [(attributes_service.common.v1.value) = "Spark"];
}

// AttributeType
enum AttributeType {
  // unknown attribute type
  ATTRIBUTE_TYPE_UNSPECIFIED = 0 [(attributes_service.common.v1.value) = "UnknownAttributeType"];

  // Standard Attribute .. the attribute keys are exposed as enums through DasherAttributeKey/AddressAttributeKey etc
  ATTRIBUTE_TYPE_STANDARD = 1 [(attributes_service.common.v1.value) = "Standard"];

  // Ephemeral Attribute .. the attribute keys are are free form text with default retention set to 90 days
  ATTRIBUTE_TYPE_EPHEMERAL = 2 [(attributes_service.common.v1.value) = "Ephemeral"];
}

// Request payload for GetBatchJobs API
message GetBatchJobsRequest {
  // get by job_id, defaults to everything
  string job_id = 1;
  // get by job_name, defaults to everything
  string job_name = 2;
  // list of jobs to find by job_states, defaults to everything
  repeated BatchJobState job_states = 3;
  // get only jobs created after, defaults to everything
  google.protobuf.Timestamp after = 4;
  // get only jobs created before, defaults to everything
  google.protobuf.Timestamp before = 5;
  // get by job owner email, defaults to everything
  string owner_email = 6;
  // get only pae_size records at a time, defaults to 10 records(max is also 10)
  int32 page_size = 7;
  // get only page_number page of pae_size records at a time, default to 1st page
  int32 page_number = 8;
  // list of fields to sort, sorting will be done across pages
  repeated NSBatchJob.BatchJobSortField sort_fields = 9;
}

// GetBatchJobResponse response payload
message GetBatchJobResponse {
  // get by job_id, defaults to everything
  string job_id = 1;
  // batchJob payload
  BatchJob batch_job = 2;
  // job created date
  google.protobuf.Timestamp created_date = 3;
  // job last updated date
  google.protobuf.Timestamp modified_date = 4;
}

// API response to GetBatchJobs
message GetBatchJobsResponse {
  // list of batch jobs matching filtering criteria
  repeated GetBatchJobResponse batch_jobs = 1;
  // get only pae_size records at a time, defaults to 10 records(max is also 10)
  int32 page_size = 2;
  // get only page_number page of pae_size records at a time, default to 1st page
  int32 page_number = 3;
  // total number of pages
  int64 total_page_count = 4;
}

// Job Metadata payload
message JobMetadata {
  // DataSource of the sql_payload
  DataSource data_source = 1;

  // list of database tables the sql payload uses
  repeated string db_tables = 2;

  // cron schedule
  oneof cron_job_schedule {
    // unit like cron schedule
    string cron_schedule = 3;

    // Predefined schedule , shuffle jobs across the clock to spread the load
    JobSchedule schedule = 4;
  }

  // To get notified about successful run of the job
  Notification success_notifications = 5;

  // To get notified about failed run of the job
  Notification failed_notifications = 6;

  // type of api
  oneof api_type {
    // segment
    Segment segment = 7;

    // attribute
    Attribute attribute = 8;
  }
}

// segment api
message Segment {
  // segment type
  attributes_service.common.v1.SegmentType segment_type = 1;
}

// attribute api
message Attribute {
  // attribute namespace
  attributes_service.common.v1.Entity attribute_namespace = 1;

  // type of the attribute that'll be generated by this batch job
  AttributeType attribute_type = 2;

  // attribute key
  string attribute_key = 3;

  // attribute data type
  attributes_service.common.v1.FieldType attribute_data_type = 4;
}

// Notification payload
message Notification {
  // owning team email
  string email = 1;
  // owning team slack
  string slack = 2;
}

// Ownership payload
message Owner {
  // owning team email
  string team_email = 1;
  // owning team slack
  string slack = 2;
}

// attribute to rank
message NSBatchJob {
  // key for batch jobs field sorting
  enum Field {
    // unspecified field
    FIELD_UNSPECIFIED = 0;

    // unique id to identify each row
    FIELD_JOB_ID = 1;

    // name of the batch job
    FIELD_JOB_NAME = 2;

    // current state of the batch job
    FIELD_JOB_STATE = 3;

    // date the job created on
    FIELD_CREATED_DATE = 4;

    // last modified date
    FIELD_MODIFIED_DATE = 5;
  }

  // sort field for BatchJob structure
  message BatchJobSortField {
    // field for sorting
    Field sort_field = 1;
    // sort order to use on the field
    attributes_service.common.v1.OrderType sort_order = 2;
  }
}

// BatchJobRunDetails namespace
message NSBatchJobRunDetails {
  // key for batch job run details
  enum Field {
    // unspecified field
    FIELD_UNSPECIFIED = 0;

    // unique id to identify each row
    FIELD_JOB_ID = 1;

    // name of the batch job
    FIELD_RUN_ID = 2;

    // current state of the batch job
    FIELD_RUN_STATE = 3;

    // time when this job start
    FIELD_START_TIME = 4;

    // time when this job ended
    FIELD_END_TIME = 5;
  }

  // sort field for RunDetails structure
  message RunDetailsSortField {
    // field for sorting
    Field sort_field = 1;
    // sort order to use on the field
    attributes_service.common.v1.OrderType sort_order = 2;
  }
}

// BatchJobRunState definitions
enum BatchJobRunState {
  // unknown schedule
  BATCH_JOB_RUN_STATE_UNSPECIFIED = 0 [(attributes_service.common.v1.value) = "Unknown"];

  // Started the job run
  BATCH_JOB_RUN_STATE_STARTED = 1 [(attributes_service.common.v1.value) = "Started"];

  // Running the SQL
  BATCH_JOB_RUN_STATE_RUNNING_SQL = 2 [(attributes_service.common.v1.value) = "RunningSQL"];

  // Finished running the SQL
  BATCH_JOB_RUN_STATE_SQL_RUN_COMPLETE = 3 [(attributes_service.common.v1.value) = "SQLRunComplete"];

  // Tagging entities returned from the SQL
  BATCH_JOB_RUN_STATE_TAGGING_ENTITIES = 4 [(attributes_service.common.v1.value) = "TaggingEntities"];

  // Finished moving data to delta table, only changed data were written
  BATCH_JOB_RUN_STATE_DONE = 5 [(attributes_service.common.v1.value) = "Done"];

  // Job run resulted in ERROR, see error_details for more information
  BATCH_JOB_RUN_STATE_ERROR = 6 [(attributes_service.common.v1.value) = "ERROR"];

  // Finished moving data to delta table, full data were written
  BATCH_JOB_RUN_STATE_DONE_WRITE_THROUGH = 7 [(attributes_service.common.v1.value) = "DoneWriteThrough"];

  // In process of moving data to delta table, full data were written
  BATCH_JOB_RUN_STATE_RUNNING_SQL_WRITE_THROUGH = 8 [(attributes_service.common.v1.value) = "RunningSQLWriteThrough"];
}

// Request payload for GetBatchJobRunDetails API
message GetBatchJobRunDetailsRequest {
  // get by job_id, defaults to everything
  string job_id = 1;
  // get by job_name, defaults to everything
  string job_name = 2;
  // list of jobs to find by run_ids, defaults to everything
  repeated string run_ids = 3;
  // get only jobs started after, defaults to everything
  google.protobuf.Timestamp after = 4;
  // get only jobs started before, defaults to everything
  google.protobuf.Timestamp before = 5;
  // get only page_size records at a time, defaults to 10 records(max is also 10)
  int32 page_size = 7;
  // get only page_number page of pae_size records at a time, default to 1st page
  int32 page_number = 8;
  // list of fields to sort, sorting will be done across pages
  repeated NSBatchJobRunDetails.RunDetailsSortField sort_fields = 9;
  // filter by job run date
  BatchJobRunState job_run_state = 10;
}

// BatchJobRunDetails response payload
message BatchJobRunDetails {
  // unique identifier for this run
  string run_id = 1;
  // job_id that we are running
  string job_id = 2;
  // job_name that we are running
  string job_name = 3;
  // job run state
  BatchJobRunState job_run_state = 4;
  // error details
  string error_details = 5;
  // timestamp when the Job Started run
  google.protobuf.Timestamp start_time = 6;
  // timestamp when the Job completed
  google.protobuf.Timestamp end_time = 7;
  // date for which the job was launched
  string run_date = 8;
}

// API response to GetBatchJobRunDetails
message GetBatchJobRunDetailsResponse {
  // list of batch_job_run_details
  repeated BatchJobRunDetails batch_job_run_details = 1;
  // get only page_size records at a time, defaults to 10 records(max is also 10)
  int32 page_size = 2;
  // get only page_number page of pae_size records at a time, default to 1st page
  int32 page_number = 3;
  // total number of pages
  int64 total_page_count = 4;
}

// Request payload for UpsertBatchJobRunDetails API
message UpsertBatchJobRunDetailsRequest {
  // unique identifier for this run. if empty it means a new run when present we'll update the corresponding batch job run details
  string run_id = 1;
  // job_name that we are running
  string job_name = 2;
  // job run state
  BatchJobRunState job_run_state = 3;
  // error details
  string error_details = 4;
  // timestamp when the Job Started run
  google.protobuf.Timestamp start_time = 5;
  // timestamp when the Job completed
  google.protobuf.Timestamp end_time = 6;
  // job id for which the job started, send either job_name or job_id
  string job_id = 7;
  // date for which the job was launched
  string run_date = 8;
}

// API response to UpsertBatchJobRunDetails
message UpsertBatchJobRunDetailsResponse {
  // unique identifier for the batch job run
  string run_id = 1;
  // job id that got upserted
  string job_id = 2;
}
