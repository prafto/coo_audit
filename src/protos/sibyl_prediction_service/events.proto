syntax = "proto3";

import "common/service_client_config.proto";
import "google/protobuf/wrappers.proto";

option go_package = "github.com/doordash/services-protobuf/generated/sibyl_prediction_service";
option java_generic_services = true;
option java_multiple_files = true;
option java_package = "com.doordash.sibyl_prediction_service.api";

// Event schema for sending prediction outputs and metadata to iguazu
message PredictionEvent {
  // Name of the Predictor in Sibyl
  string predictor_name = 1;
  // Model ID that was used for the above Predictor.
  string model_id = 2;
  // If the prediction was made on a default model.
  bool is_default_model = 3;
  // If this event is from shadow prediction
  bool is_shadow_prediction = 11;
  // Feature set ID that was specified in the prediction request.
  string feature_set_id = 4;
  // Timestamp for when prediction response was generated in nanoseconds.
  int64 prediction_ts = 5;
  // Full set of features used to make the prediction.
  map<string, string> features = 6;
  // The Prediction that was returned in the response.
  float prediction_result = 7;
  // For which features, did we use default values?
  // The key is the name of the feature.
  // The value must be 1.
  map<string, int32> default_values_used = 8;
  // Store by name, the outputs associated to a prediction as string
  // Example: "confidence_score": "0.1"
  // Uses string format because we can't nest protobuf objects for logging yet
  // TODO: Change to prediction_tensor once nested protobufs are available
  map<string, string> prediction_tensor_str = 9;
  // Use-Case for the Prediction
  string prediction_use_case = 10;
}
