syntax = "proto3";

package com.doordash.iguazu;

option go_package = "github.com/doordash/services-protobuf/generated/iguazu";

/*
   See https://docs.google.com/document/d/1xXSHLy0zS1YKgHPHSyvkI1XIgNGQhQmzg8NcH5brbBM/edit?usp=sharing
   for complete design doc
   
   Serialization for int32 and int64: Please follow the Java API specification for DataOutputStream.writeInt()
   and writeLong()
   
   Serialization for string should use UTF-8 encoding
*/
enum SerializationFormat {
  UNKNOWN_FORMAT = 0;

  // Protobuf binaries encoding
  PROTO = 1; // "proto"

  // Protobuf JSON encoding
  PROTO_JSON = 2; // "proto-json"

  // Avro binary encoding
  AVRO = 3; // "avro"

  // Protobuf binary encoding (in header) and
  PROTO_AVRO = 4; // "proto+avro"

  // JSON encoding
  JSON = 5;
}

message KafkaHeaders {
  // High level event name, like "PaymentReceived"
  string _EVENT_NAME_ = 1;

  // Event time as long
  int64 _EVENT_TIME_ = 2;

  // Avro schema ID if available
  int32 _SCHEMA_ID_ = 3;

  // Fully qualified protobuf class name
  string _PROTOBUF_CLASS_ = 4;

  // Unique message ID for idempotency
  string _IDEMPOTENCY_KEY_ = 5;

  // Serialization format.
  SerializationFormat _SERIALIZATION_FORMAT_ = 6;

  // Source where the event is originally generated
  string _SOURCE_ = 7;

  // Doordash entity name, for example, "dasher"
  string _ENTITY_NAME_ = 8;

  // ID of the Doordash entity involved in the event
  string _ENTITY_ID_ = 9;

  // raw protobuf encoded bytes, used in header when _SERIALIZATION_FORMAT_=proto+avro
  bytes _PROTOBUF_VALUE = 10;

  // JSON encoded map for any custom attributes specific to the data transport
  string _CUSTOM_ATTRIBUTES_ = 11;

  // envelope version starting with 0.
  int32 _VERSION_ = 12;

  // Event version starting with 0. Default as 0.
  int32 _EVENT_VERSION_ = 13;

  // Region that event originated from. values will be like us-west-2 , eu-west-1. This will help our international expansion. Default is us-west-2 if it is empty
  string _REGION_ = 14;

  // The timestamp of the event when persisted in Kafka
  int64 _KAFKA_TIMESTAMP_ = 15;

  // Kafka partition
  int32 _KAFKA_PARTITION_ = 16;

  // Kafka offset
  int64 _KAFKA_OFFSET_ = 17;

  // Kafka topic
  string _KAFKA_TOPIC_ = 18;

  // next index 19
}
