syntax = "proto3";

package conductor_service.v1;

import "google/protobuf/timestamp.proto";
import "google/protobuf/wrappers.proto";

option go_package = "conductor_service";
option java_generic_services = true;
option java_multiple_files = true;
option java_package = "com.doordash.rpc.conductor_service";

// This is a placeholder
// The greeting service definition
service GreeterService {
  // Sends a greeting
  rpc SayHello(SayHelloRequest) returns (SayHelloResponse) {}
}

// The request message containing the user's name
message SayHelloRequest {
  // name
  string name = 1;
}

// The response message containing the greetings
message SayHelloResponse {
  // name
  string message = 1;
}

// Service to log ETL tasks
service TaskLogService {
  // Log ETL task status
  rpc LogTaskStatus(LogTaskStatusRequest) returns (LogTaskStatusResponse) {}
  // Get ETL Task status
  rpc GetTaskStatus(GetTaskStatusRequest) returns (GetTaskStatusResponse) {}
}

// enums

// Warehouse type
enum WarehouseType {
  // Unspecified
  WAREHOUSE_TYPE_UNSPECIFIED = 0;
  // Snowflake
  WAREHOUSE_TYPE_SNOWFLAKE = 1;
  // Datalake
  WAREHOUSE_TYPE_DATALAKE = 2;
}

// Domain type
enum DomainType {
  // Unspecified
  DOMAIN_TYPE_UNSPECIFIED = 0;
  // Common
  DOMAIN_TYPE_COMMON = 1;
}

// Event type
enum EventType {
  // Unspecified
  EVENT_TYPE_UNSPECIFIED = 0;
  // Success
  EVENT_TYPE_SUCCESS = 1;
  // Start
  EVENT_TYPE_START = 2;
  // Fail
  EVENT_TYPE_FAIL = 3;
  // Backfill
  EVENT_TYPE_BACKFILL = 4;
  // Create
  EVENT_TYPE_CREATE = 5;
}

// Worflow type
enum WorkflowType {
  // Unspecified workflow type
  WORKFLOW_TYPE_UNSPECIFIED = 0;
  // Airflow workflow type
  WORKFLOW_TYPE_AIRFLOW = 1;
  // Dagster workflow type
  WORKFLOW_TYPE_DAGSTER = 2;
  // Databricks workflow type
  WORKFLOW_TYPE_DATABRICKS_WORKFLOW = 3;
  // Streaming workflow type
  WORKFLOW_TYPE_STREAMING = 4;
}

// Task type
enum TaskType {
  // Task type is unspecified
  TASK_TYPE_UNSPECIFIED = 0;
  // Task type for Snowflake transform table
  TASK_TYPE_SNOWFLAKE_TRANSFORM_TABLE = 1;
  // Task type for Delta transform table
  TASK_TYPE_DELTA_TRANSFORM_TABLE = 2;
  // Task type for Ice transform table
  TASK_TYPE_ICE_TRANSFORM_TABLE = 3;
  // Task type for Snowflake Pepto import
  TASK_TYPE_SNOWFLAKE_PEPTO_IMPORT = 4;
  // Task type for Delta Pepto CDC
  TASK_TYPE_DELTA_PEPTO_CDC = 5;
  // Task type for Delta Pepto snapshot
  TASK_TYPE_DELTA_PEPTO_SNAPSHOT = 6;
  // Task type for Iguazu Delta
  TASK_TYPE_IGUAZU_DELTA = 7;
  // Task type for Iguazu Ice
  TASK_TYPE_IGUAZU_ICE = 8;
  // Task type for Snowflake S3 export
  TASK_TYPE_SNOWFLAKE_S3_EXPORT = 9;
  // Task type for Snowflake S3 import
  TASK_TYPE_SNOWFLAKE_S3_IMPORT = 10;
  // Task type for Data Lake S3 export
  TASK_TYPE_DATALAKE_S3_EXPORT = 11;
  // Task type for Data Lake S3 import
  TASK_TYPE_DATALAKE_S3_IMPORT = 12;
  // Task type for Data Lake Google Sheet
  TASK_TYPE_DATA_LAKE_GSHEET = 13;
  // Task type for Snowflake Google Sheet
  TASK_TYPE_SNOWFLAKE_GSHEET = 14;
  // Task type for Snowflake forecast
  TASK_TYPE_SNOWFLAKE_FORECAST = 15;
  // Task type for Data Lake forecast
  TASK_TYPE_DATA_LAKE_FORECAST = 16;
  // Task type for Snowflake RCOPY
  TASK_TYPE_SNOWFLAKE_RCOPY = 17;
  // Task type for Data Lake RCOPY
  TASK_TYPE_DATALAKE_RCOPY = 18;
  // Task type for Snowflake Firefly metric
  TASK_TYPE_SNOWFLAKE_FIREFLY_METRIC = 19;
  // Task type for Snowflake Firefly measure
  TASK_TYPE_SNOWFLAKE_FIREFLY_MEASURE = 20;
  // Task type for Data Lake Firefly metric
  TASK_TYPE_DATA_LAKE_FIREFLY_METRIC = 21;
  // Task type for Data Lake Firefly measure
  TASK_TYPE_DATA_LAKE_FIREFLY_MEASURE = 22;
  // Task type for Snowflake Cassandra import
  TASK_TYPE_SNOWFLAKE_CASSANDRA_IMPORT = 23;
  // Task type for Data Lake Cassandra import
  TASK_TYPE_DATALAKE_CASSANDRA_IMPORT = 24;
  // Task type for Snowflake Postgres import
  TASK_TYPE_SNOWFLAKE_POSTGRES_IMPORT = 25;
  // Task type for Snowflake other import
  TASK_TYPE_SNOWFLAKE_OTHER_IMPORT = 26;
  // Task type for Snowflake SFTP export
  TASK_TYPE_SNOWFLAKE_SFTP_EXPORT = 27;
  // Task type for Snowflake SFTP import
  TASK_TYPE_SNOWFLAKE_SFTP_IMPORT = 28;
  // Task type for Data Lake SFTP export
  TASK_TYPE_DATALAKE_SFTP_EXPORT = 29;
  // Task type for Data Lake SFTP import
  TASK_TYPE_DATALAKE_SFTP_IMPORT = 30;
  // Task type for Snowflake Cassandra export
  TASK_TYPE_SNOWFLAKE_CASSANDRA_EXPORT = 31;
  // Task type for Data Lake Cassandra export
  TASK_TYPE_DATALAKE_CASSANDRA_EXPORT = 32;
  // Task type for Snowflake X360 entity
  TASK_TYPE_SNOWFLAKE_X360_ENTITY = 33;
  // Task type for Snowflake X360 attribute
  TASK_TYPE_SNOWFLAKE_X360_ATTRIBUTE = 34;
  // Task type for Snowflake X360 attribute set
  TASK_TYPE_SNOWFLAKE_X360_ATTRIBUTESET = 35;
  // Task type for Data Lake X360 entity
  TASK_TYPE_DATALAKE_X360_ENTITY = 36;
  // Task type for Data Lake X360 attribute
  TASK_TYPE_DATALAKE_X360_ATTRIBUTE = 37;
  // Task type for Data Lake X360 attribute set
  TASK_TYPE_DATALAKE_X360_ATTRIBUTESET = 38;
}

// Hubble Tier
enum HubbleTier {
  // Unspecified Hubble Tier
  HUBBLE_TIER_UNSPECIFIED = 0;
  // Bronze Hubble Tier
  HUBBLE_TIER_BRONZE = 1;
  // Silver Hubble Tier
  HUBBLE_TIER_SILVER = 2;
  // Gold Hubble Tier
  HUBBLE_TIER_GOLD = 3;
}

// Table Load Type
enum TableLoadType {
  // Unspecified table load type
  TABLE_LOAD_TYPE_UNSPECIFIED = 0;
  // Transactional table load type
  TABLE_LOAD_TYPE_TRANSACTIONAL = 1;
  // Append-only table load type
  TABLE_LOAD_TYPE_APPEND_ONLY = 2;
  // Snapshot table load type
  TABLE_LOAD_TYPE_SNAPSHOT = 3;
  // SCD table load type
  TABLE_LOAD_TYPE_SCD = 4;
}

// Hubble Component
enum HubbleComponent {
  // Unspecified Hubble Component
  HUBBLE_COMPONENT_UNSPECIFIED = 0;
  // Core Finance Hubble Component
  HUBBLE_COMPONENT_CORE_FINANCE = 1;
  // Core Invoicing Hubble Component
  HUBBLE_COMPONENT_CORE_INVOICING = 2;
  // Core MX Hubble Component
  HUBBLE_COMPONENT_CORE_MX = 3;
  // Core OpEx Hubble Component
  HUBBLE_COMPONENT_CORE_OPEX = 4;
}

// Hubble Element
enum HubbleElement {
  // Unspecified Hubble Element
  HUBBLE_ELEMENT_UNSPECIFIED = 0;
  // Billing Hubble Element
  HUBBLE_ELEMENT_BILLING = 1;
  // Menus Hubble Element
  HUBBLE_ELEMENT_MENUS = 2;
  // Promos Hubble Element
  HUBBLE_ELEMENT_PROMOS = 3;
}

// Hubble Domain
enum HubbleDomain {
  // Unspecified Hubble Domain
  HUBBLE_DOMAIN_UNSPECIFIED = 0;
  // Accounting Hubble Domain
  HUBBLE_DOMAIN_ACCOUNTING = 1;
  // Consumer Hubble Domain
  HUBBLE_DOMAIN_CONSUMER = 2;
  // Finance Hubble Domain
  HUBBLE_DOMAIN_FINANCE = 3;
  // Foundational/Core Hubble Domain
  HUBBLE_DOMAIN_FOUNDATIONAL_CORE = 4;
  // Growth Hubble Domain
  HUBBLE_DOMAIN_GROWTH = 5;
  // Logistics Hubble Domain
  HUBBLE_DOMAIN_LOGISTICS = 6;
  // Marketing Hubble Domain
  HUBBLE_DOMAIN_MARKETING = 7;
  // OpEx Hubble Domain
  HUBBLE_DOMAIN_OPEX = 8;
  // Payments & Invoicing Hubble Domain
  HUBBLE_DOMAIN_PAYMENTS_INVOICING = 9;
}

// mesages

// hubble details
message HubbleDetails {
  // hubble domain
  HubbleDomain hubble_domain = 1;
  // hubble component
  HubbleComponent hubble_component = 2;
  // hubble element
  HubbleElement hubble_element = 3;
  // hubble tier
  HubbleTier hubble_tier = 4;
}

// task
message Task {
  // optional - task_id : Hash of task_name, task_type and warehouse_type
  google.protobuf.StringValue task_id = 1;
  // reqired - Name of the Process, e.g coredb.restricted.metrics_repo ,
  // company_performance_dashboard_refresh,
  // s3_export_coredb_restricted_metrics_repo
  google.protobuf.StringValue task_name = 2;
  // task_tag
  map<string, string> task_tag = 3 [deprecated = true];
  // Applicable for processType
  TaskType task_type = 4;
  // task_owner
  map<string, string> task_owner = 5 [deprecated = true];
  // A brief description of process, this will be taken from doc string of respective Dag/Task
  google.protobuf.StringValue task_details = 6;
  // reqired - warehouse_type
  WarehouseType warehouse_type = 7;
  // table_load_type
  TableLoadType table_load_type = 8;
  // huble details
  HubbleDetails hubble_details = 9;
  // Array of Strings - Tags can be like - SOT/GOLD/SOX etc
  repeated google.protobuf.StringValue task_tags = 10;
  // Owner of the process - TeamDL or Person
  repeated google.protobuf.StringValue task_owners = 11;
}

// log run
message LogRun {
  // task_run_id
  google.protobuf.StringValue task_run_id = 1;
  // Instanceid of respective process_id, dag_id and task_id
  google.protobuf.StringValue instance_id = 2;
  // Timestamp of DagSchedule, This is the actual schedule time not the RunTime
  google.protobuf.Timestamp workflow_schedule_time = 3;
  // event_type
  EventType event_type = 4;
  // Timestamp when the respective event was occured
  google.protobuf.Timestamp event_time = 5;
  // Timestamp till when the respective table has the data. This is further leveraged in Sensor - Downstream dependencies
  google.protobuf.Timestamp as_of_data_time_low_water_mark = 6;
  // optional - Timestamp till when the respective table has the data. This is further leveraged in Sensor - Downstream dependencies
  google.protobuf.Timestamp as_of_data_time_high_water_mark = 7;
  // optional
  map<string, string> task_run_details = 8;
}

// register workflow
message Workflow {
  // workflow type
  WorkflowType workflow_type = 1;
  // For Airflow its DagID, for DBR workflows its WorkflowName etc.
  google.protobuf.StringValue workflow_id = 2;
  // For Airflow its respective AirflowTaskID in the Dag, for DBR workflows it can be the NULL or same as workflow name.
  google.protobuf.StringValue workflow_task_id = 3;
  //For Airflow its DDSnowflakeTargetLoadOperator/DDS3ExportOperator/DDTableauExtractOperator etc
  google.protobuf.StringValue workflow_task_type = 4;
  // Cron schedule of workflow - in mins - 60, 240 etc
  google.protobuf.UInt32Value workflow_schedule_freq_mins = 5;
  // A boolean value indicating, if this respective dag/task
  // is the primary producer of respective table.
  // This is leveraged in Sensor - downstream dependencies
  google.protobuf.BoolValue is_primary_producer = 6;
  // Timezone of the workflow
  google.protobuf.StringValue workflow_timezone = 7;
  // Cron schedule of workflow
  google.protobuf.StringValue workflow_cron_schedule = 8;
}

// The request message containing ETL log request
message LogTaskStatusRequest {
  // log
  LogRun log_run = 1;
  // task
  Task task = 2;
  // workflow
  Workflow workflow = 3;
}

// The response message containing ETL log response
message LogTaskStatusResponse {
  // task id
  google.protobuf.StringValue task_id = 1;
  // error
  google.protobuf.StringValue error = 2;
}

// The request message to get task status
message GetTaskStatusRequest {
  // task id or table name
  oneof value {
    // task id
    google.protobuf.StringValue task_id = 1;
    // task name
    google.protobuf.StringValue task_name = 2;
  }
  // Timestamp of DagSchedule, This is the actual schedule time not the RunTime
  google.protobuf.Timestamp workflow_schedule_time = 3 [deprecated = true];
  // For Airflow its DagID, for DBR workflows its WorkflowName etc.
  google.protobuf.StringValue workflow_id = 4;
  // Cron schedule of workflow - in mins - 60, 240 etc
  google.protobuf.UInt32Value workflow_schedule_freq_mins = 5;
  // low offset
  google.protobuf.UInt32Value low_offset = 6;
  // high offset
  google.protobuf.UInt32Value high_offset = 7;
  // downstream_workflow_schedule_time
  google.protobuf.Timestamp downstream_workflow_schedule_time = 8;
}

// The request message containing ETL end
message GetTaskStatusResponse {
  // completed
  google.protobuf.BoolValue completed = 1 [deprecated = true];
  // error
  google.protobuf.StringValue error = 2;
  // task name
  google.protobuf.StringValue task_name = 3;
  // For Airflow its DagID, for DBR workflows its WorkflowName etc.
  google.protobuf.StringValue workflow_id = 4;
  // For Airflow its respective AirflowTaskID in the Dag, for DBR workflows it can be the NULL or same as workflow name.
  google.protobuf.StringValue workflow_task_id = 5;
  // Cron schedule of workflow - in mins - 60, 240 etc
  google.protobuf.UInt32Value workflow_schedule_freq_mins = 6;
  // Timestamp till when the respective table has the data. This is further leveraged in Sensor - Downstream dependencies
  google.protobuf.Timestamp as_of_data_time_low_water_mark = 7;
  // run details
  map<string, string> run_details = 8;
}
